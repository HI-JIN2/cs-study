# Kafka와 CQRS 패턴 (0129)

## 1. Apache Kafka

### 1) 개요
*   **등장 배경**: LinkedIn에서 파편화된 데이터 수집 및 분배의 어려움을 해결하기 위해 개발.
*   **기능**:
    *   애플리케이션 간의 1:1 연결(Coupling)을 끊고, 중앙 집중화된 데이터 처리.
    *   대용량 데이터를 실시간 스트림으로 관리하는 중추 신경 역할.
    *   소스(Source) 애플리케이션은 카프카로 데이터를 보내고(Producer), 타겟(Target) 애플리케이션은 카프카에서 데이터를 가져감(Consumer).
*   **구조**: Queue (FIFO) 방식.
*   **운영**: 상용 환경에서는 최소 3대 이상의 서버(Broker)로 클러스터 구성하여 고가용성 확보. (Netflix의 경우 수천 개의 브로커 운영)

### 2) 사용 이유
*   **높은 처리량**: 대량의 실시간 트래픽 처리 가능.
*   **확장성**: Scale-In / Scale-Out이 쉽고 무중단 수행 가능.
*   **영속성**: 데이터를 메모리가 아닌 파일 시스템에 저장하여 재부팅 후에도 데이터 보존.
*   **고가용성**: 클러스터링을 통해 일부 서버 장애 시에도 무중단 서비스 가능.

### 3) Kafka 설치 (Docker Compose)
`docker-compose.yml` 파일을 이용한 설치 예시:

```yaml
services:
  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
```

*   **실행**: `docker-compose up -d`
*   **설정 변경**: 컨테이너 내부 `server.properties` 수정 필요.
    *   `listeners=PLAINTEXT://:9092`
    *   `delete.topic.enable=true`, `auto.create.topics.enable=true`

### 4) Kafka 명령어 실습
컨테이너 접속 후 `/opt/kafka/bin` 경로에서 실행.

*   **Topic 생성**:
    ```bash
    kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 1 --partitions 1 --topic exam-topic
    ```
*   **Topic 조회**:
    ```bash
    kafka-topics.sh --bootstrap-server localhost:9092 --list
    ```
*   **메시지 발행 (Producer)**:
    ```bash
    kafka-console-producer.sh --topic exam-topic --broker-list localhost:9092
    ```
*   **메시지 구독 (Consumer)**:
    ```bash
    kafka-console-consumer.sh --topic exam-topic --bootstrap-server localhost:9092 --from-beginning
    ```

---

## 2. CQRS (Command and Query Responsibility Segregation)

### 1) 개요
*   **정의**: 데이터 저장소로부터 **읽기(Query)**와 **쓰기(Command)**의 책임(모델)을 분리하는 패턴.
*   **목적**: 퍼포먼스, 확장성, 보안성 극대화 및 도메인 복잡성 해결.

### 2) 전통적 방식의 문제점
*   읽기와 쓰기에 동일한 데이터 모델 사용 -> 복잡성 증가.
*   읽기/쓰기 부하의 불균형(보통 읽기가 훨씬 많음) 및 최적화 어려움.
*   보안 관리의 복잡성 및 데이터 경합(Lock) 발생.

### 3) CQRS의 특징 및 장점
*   **명령(Command)**: 데이터를 변경(CUD). 비동기 큐 처리 권장.
*   **쿼리(Query)**: 데이터를 조회(R). 데이터 변경 불가, DTO 반환.
*   **물리적 분리**:
    *   **쓰기 DB**: RDBMS (MySQL 등) - 무결성, 비즈니스 로직 중심.
    *   **읽기 DB**: NoSQL (MongoDB, ElasticSearch 등) - 조회 성능 최적화, 역정규화된 스키마.
*   **동기화**: 쓰기 발생 시 이벤트를 발행하여 읽기 DB로 데이터 전파 (Event Sourcing).
*   **장점**:
    *   **독립적 스케일링**: 읽기 서버만 증설 가능.
    *   **최적화된 스키마**: 조회 용도에 맞는 DB 사용.
    *   **단순화**: 복잡한 조인 없이 조회 가능 (Materialized View).

### 4) 고려사항
*   **복잡성 증가**: 시스템 아키텍처가 복잡해짐.
*   **데이터 일관성**: 읽기 DB 업데이트 지연(Delay)으로 인한 일시적 불일치 발생 가능.

---

## 3. CQRS 구현 예시 (Django + MongoDB + Kafka)

### 1) 아키텍처 구성
*   **Framework**: Django (Python), React (Frontend)
*   **Write DB**: MySQL/PostgreSQL (RDBMS)
*   **Read DB**: MongoDB (NoSQL)
*   **Message Broker**: Kafka (데이터 동기화)

### 2) 구현 단계 요약
1.  **쓰기 서비스 (Write App)**:
    *   RDBMS 모델 정의 (`Book` 테이블).
    *   데이터 저장(`POST`) 시 RDBMS에 저장하고, **Kafka Topic (`cqrstopic`)에 이벤트 발행**.
    *   메시지 내용: `{"task": "insert", "data": {...}}`

    ```python
    # Producer 예시
    producer.send(topic, value=msg)
    ```

2.  **읽기 서비스 (Read App)**:
    *   MongoDB 연결.
    *   **Kafka Consumer**가 실행되어 `cqrstopic` 데이터를 구독.
    *   데이터 수신 시 **MongoDB에 데이터 저장/동기화**.
    *   사용자 조회(`GET`) 요청 시 MongoDB에서 데이터 조회하여 반환.

    ```python
    # Consumer 예시
    for message in consumer:
        data = json.loads(message.value)
        collection.insert_one(data)
    ```

3.  **동기화 로직**:
    *   앱 시작 시 RDBMS 데이터를 읽어 MongoDB를 초기화하는 로직(`ready()` 메서드 등)을 추가하여 정합성 보장 가능.
